#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
opt_atomic.py

ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œæ‰“åŒ…å›¾ç‰‡ä¸º .tarï¼Œå¹¶é€šè¿‡æ‰«æå·²æœ‰ .tar æ¥å®ç°æ–­ç‚¹ç»­ä¼ ï¼ˆcheckpointï¼‰ã€‚
æ¯ä¸ªå­è¿›ç¨‹è´Ÿè´£å°†ä¸€ä¸ª samples_per_tar å¤§å°çš„å›¾ç‰‡å—æ‰“åŒ…æˆä¸€ä¸ª .tar.tmpï¼Œå®ŒæˆååŸå­é‡å‘½åä¸º .tarã€‚
é‡å¯æ—¶åªéœ€æ‰«æ output_root ä¸‹å·²æœ‰çš„ .tar æ–‡ä»¶ï¼Œè·³è¿‡å¯¹åº”çš„å—ç´¢å¼•ï¼Œé¿å…é‡å¤å¤„ç†ã€‚
"""

import os
import uuid
import tarfile
import json
from PIL import Image
from io import BytesIO
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm

# === å‚æ•°é…ç½® ===
input_root      = "/home/iv/images/new_aws_pics/2021"   # è¾“å…¥å›¾ç‰‡æ ¹ç›®å½•
output_root     = "/home/iv/images/new_aws_tar_v2"        # è¾“å‡º .tar ä¿å­˜æ ¹ç›®å½•
samples_per_tar = 10000                                 # æ¯ä¸ª .tar åŒ…å«çš„å›¾ç‰‡æ•°é‡
tars_per_group  = 500                                   # æ¯ tars_per_group ä¸ª .tar å½’åˆ°ä¸€ä¸ªå­ç›®å½• group_xxx
max_workers     = 48                                     # å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œå»ºè®®è®¾ç½®ä¸º CPU æ ¸æ•°çš„ä¸€åŠæˆ–ç›¸è¿‘
image_suffixes  = {".jpg", ".jpeg", ".png", ".webp"}    # æ”¯æŒçš„å›¾ç‰‡åç¼€

# å¯ä»¥æŒ‰éœ€ä¿®æ”¹ start_group / start_tarï¼Œä»¥æ”¯æŒè·¨ä½œä¸šç»§ç»­
start_group = 0
start_tar   = 5227

os.makedirs(output_root, exist_ok=True)


def get_finished_indices(output_root: str, tars_per_group: int) -> set[int]:
    """
    æ‰«æ output_root ä¸‹æ‰€æœ‰ group_* ç›®å½•ï¼Œæ”¶é›†å·²å­˜åœ¨çš„ .tar æ–‡ä»¶å¯¹åº”çš„ tar_indexã€‚
    tar_index = int(â€œ000123.tarâ€.replace(".tar",""))
    è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰å·²å®Œæˆ tar_index çš„é›†åˆã€‚
    """
    finished = set()
    # åˆ—å‡ºæ‰€æœ‰ä»¥ â€œgroup_â€ å¼€å¤´çš„å­ç›®å½•
    for entry in os.listdir(output_root):
        if not entry.startswith("group_"):
            continue
        group_dir = os.path.join(output_root, entry)
        if not os.path.isdir(group_dir):
            continue
        # åˆ—å‡ºæœ¬ç»„ä¸‹æ‰€æœ‰ .tar æ–‡ä»¶
        for fname in os.listdir(group_dir):
            if not fname.endswith(".tar"):
                continue
            try:
                idx = int(fname[:-4])  # â€œ000123.tarâ€ å»æ‰ â€œ.tarâ€ åè½¬ int â†’ 123
                finished.add(idx)
            except ValueError:
                # å¦‚æœæ–‡ä»¶åä¸æ˜¯äº”ä½æ•°å­—.tarï¼Œåˆ™ç•¥è¿‡
                continue
    return finished


def process_and_write_atomic(paths_block: list[str],
                             tar_index: int,
                             output_root: str,
                             tars_per_group: int) -> bool:
    """
    å­è¿›ç¨‹ä»»åŠ¡ï¼šå°†ä¸€ä¸ªé•¿åº¦ä¸º samples_per_tar çš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨ paths_block
    æ‰“åŒ…æˆä¸€ä¸ª .tar.tmpï¼Œå®ŒæˆååŸå­é‡å‘½åä¸º .tarï¼Œå¹¶ç”ŸæˆåŒç›®å½•ä¸‹çš„ç»Ÿè®¡ .json æ–‡ä»¶ã€‚

    è¿”å› True è¡¨ç¤ºè¯¥å—æ‰“åŒ…å¹¶å†™å…¥æˆåŠŸï¼›False è¡¨ç¤ºå¤±è´¥ã€‚
    """
    # è®¡ç®—æœ¬ tar_index åº”è¯¥å­˜æ”¾åˆ°å“ªä¸ª group_{:05d} ç›®å½•
    group_id   = tar_index // tars_per_group
    group_dir  = os.path.join(output_root, f"group_{group_id:05d}")
    os.makedirs(group_dir, exist_ok=True)

    final_tar = os.path.join(group_dir, f"{tar_index:05d}.tar")
    tmp_tar   = final_tar + ".tmp"

    # å¦‚æœ final_tar å·²å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡
    if os.path.exists(final_tar):
        return True

    # 1. æ‰“åŒ…åˆ° tmp æ–‡ä»¶
    success = 0
    try:
        with tarfile.open(tmp_tar, "w") as tar:
            for path in paths_block:
                try:
                    with Image.open(path) as img:
                        img = img.convert("RGB")
                        width, height = img.size
                        buf = BytesIO()
                        img.save(buf, format="JPEG")
                        img_bytes = buf.getvalue()
                    key = str(uuid.uuid4())
                    # å†™å…¥ JPEG
                    info_jpg = tarfile.TarInfo(name=f"{key}.jpg")
                    info_jpg.size = len(img_bytes)
                    tar.addfile(info_jpg, BytesIO(img_bytes))
                    # å†™å…¥ JSON å…ƒä¿¡æ¯
                    meta = {
                        "filename": os.path.basename(path),
                        "width": width,
                        "height": height,
                    }
                    json_bytes = json.dumps(meta, ensure_ascii=False).encode("utf-8")
                    info_json = tarfile.TarInfo(name=f"{key}.json")
                    info_json.size = len(json_bytes)
                    tar.addfile(info_json, BytesIO(json_bytes))
                    success+=1
                except Exception as e_img:
                    print(f"âŒ [Chunk {tar_index}] å¤„ç†å›¾ç‰‡å‡ºé”™: {path} â†’ {e_img}")
                    # å¦‚æœå•å¼ å›¾ç‰‡è§£ç æˆ–å†™å…¥å¤±è´¥ï¼Œåˆ™è·³è¿‡è¯¥å›¾ç‰‡ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                    continue
    except Exception as e_tar:
        # æ‰“åŒ…é˜¶æ®µå‡ºé”™ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶å¹¶è¿”å› False
        if os.path.exists(tmp_tar):
            os.remove(tmp_tar)
        print(f"âŒ [Chunk {tar_index}] æ‰“åŒ…åˆ° tmp æ–‡ä»¶å¤±è´¥: {e_tar}")
        return False

    # 2. åŸå­æ€§é‡å‘½åï¼štmp â†’ final
    try:
        os.rename(tmp_tar, final_tar)
    except Exception as e_rename:
        # å¦‚æœé‡å‘½åå¤±è´¥ï¼Œåˆ é™¤ tmp å¹¶è¿”å› False
        if os.path.exists(tmp_tar):
            os.remove(tmp_tar)
        print(f"âŒ [Chunk {tar_index}] é‡å‘½å .tmp å¤±è´¥: {e_rename}")
        return False

    # 3. å†™ç»Ÿè®¡ JSONï¼Œä¸ final_tar åŒç›®å½•ä¸‹åŒå .json
    try:
        count_info = {
            "tar_file": os.path.basename(final_tar),
            "image_count": success
        }
        count_json_path = final_tar.replace(".tar", ".json")
        with open(count_json_path, "w", encoding="utf-8") as f_json:
            json.dump(count_info, f_json, ensure_ascii=False, indent=2)
    except Exception as e_count:
        print(f"âš ï¸ [Chunk {tar_index}] å†™ç»Ÿè®¡ JSON å¤±è´¥: {e_count}")

    print(f"âœ… [Chunk {tar_index}] å†™å…¥æˆåŠŸ: {final_tar} ({len(paths_block)} å¼ å›¾ç‰‡)")
    return True


def main():
    # 1. æŒ‰ç…§æ‰©å±•åæ”¶é›†æ‰€æœ‰å›¾ç‰‡è·¯å¾„ï¼ˆé™æ€åˆ—è¡¨ï¼‰ï¼Œå¹¶æ’åºï¼Œä¿è¯ chunk åˆ†é…å›ºå®š
    all_paths = []
    for dirpath, _, filenames in os.walk(input_root):
        for fname in filenames:
            ext = os.path.splitext(fname)[1].lower()
            if ext in image_suffixes:
                all_paths.append(os.path.join(dirpath, fname))
    all_paths.sort()

    total_images = len(all_paths)
    if total_images == 0:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æ”¯æŒæ ¼å¼çš„å›¾ç‰‡ã€‚")
        return

    print(f"ğŸ“‚ å…±å‘ç° {total_images} å¼ å¾…å¤„ç†å›¾ç‰‡ (å«å­ç›®å½•)ã€‚")

    # 2. è®¡ç®—æ€»å…±å¤šå°‘ä¸ªå—ï¼ˆchunkï¼‰
    total_chunks = (total_images + samples_per_tar - 1) // samples_per_tar
    print(f"ğŸ”¢ é¢„è®¡åˆ† {total_chunks} ä¸ªå—ï¼Œæ¯å— â‰ˆ {samples_per_tar} å¼ å›¾ç‰‡ã€‚")

    # 3. æ‰«æå·²æœ‰ .tarï¼Œç”Ÿæˆå·²å®Œæˆçš„ tar_index é›†åˆ
    finished_indices = get_finished_indices(output_root, tars_per_group)
    if finished_indices:
        print(f"ğŸ” æ£€æµ‹åˆ°å·²æœ‰ {len(finished_indices)} ä¸ªå·²å®Œæˆçš„ .tar å—ï¼Œå°†è‡ªåŠ¨è·³è¿‡å®ƒä»¬ã€‚")
    else:
        print("ğŸ”„ æœªæ£€æµ‹åˆ°å·²å®Œæˆçš„ .tarå—ï¼Œå°†å…¨éƒ¨é‡æ–°æ‰“åŒ…ã€‚")

    # 4. æŒ‰å—å¹¶è¡Œæäº¤åˆ°è¿›ç¨‹æ± 
    futures = []
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        pbar = tqdm(total=total_chunks, desc="Chunks", unit="tar")
        for chunk_idx in range(total_chunks):
            tar_index = start_group * tars_per_group + start_tar + chunk_idx
            if tar_index in finished_indices:
                # è·³è¿‡å·²å®Œæˆçš„ tar_indexï¼Œå¹¶æ›´æ–°è¿›åº¦æ¡
                pbar.update(1)
                continue

            # è¯¥å—çš„å›¾ç‰‡ç´¢å¼•èŒƒå›´ï¼š[chunk_idx * samples_per_tar : (chunk_idx+1) * samples_per_tar)
            start_i = chunk_idx * samples_per_tar
            end_i   = min(start_i + samples_per_tar, total_images)
            paths_block = all_paths[start_i:end_i]

            # æäº¤å­è¿›ç¨‹ä»»åŠ¡
            future = executor.submit(
                process_and_write_atomic,
                paths_block,
                tar_index,
                output_root,
                tars_per_group
            )
            futures.append(future)


        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for fut in as_completed(futures):
            pbar.update(1)
            # å–å›è¿”å›å€¼ (True/False)ï¼Œå¯ç”¨äºæ£€æŸ¥å¤±è´¥çš„å—
            success = fut.result()
            # ç«‹å³æ›´æ–°è¿›åº¦æ¡ (ä»»åŠ¡å·²æäº¤ï¼Œç›¸å½“äºâ€œå ç”¨ä¸€ä¸ªæ§½â€)
        pbar.close()

    print("âœ… å…¨éƒ¨ä»»åŠ¡å®Œæˆã€‚")


if __name__ == "__main__":
    main()
